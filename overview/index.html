<!doctype html>
<html lang='en'>
<head>
<title></title>
<meta charset='utf-8'>
<meta name='viewport' content='width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0'>
<script src='list.js'></script>
<script src='page.js'></script>
<script src='http://mrdoob.github.com/three.js/examples/js/Detector.js'></script>
<script src='http://mrdoob.github.com/three.js/build/three.min.js'></script>
<script src='http://mrdoob.github.com/three.js/examples/js/controls/TrackballControls.js'></script>
<script src='http://mrdoob.github.com/three.js/examples/js/libs/stats.min.js'></script>
<link type='text/css' rel='stylesheet' href='page.css' />
</head>
<body>
<script>
	if ( ! Detector.webgl ) { Detector.addGetWebGLMessage(); }

	var renderer, scene, camera, controls, stats;
	var cube, plane, colors = [];
	
	var clock = new THREE.Clock();

	init();
	animate();
	
	var group;
	var scans;
	group = new THREE.Object3D();

	function init() {
		if ( ! Detector.webgl ) {
			renderer = new THREE.CanvasRenderer( { antialias: true } );
		} else {
			renderer = new THREE.WebGLRenderer( { alpha: 1, antialias: true, clearColor: 0xffffff } );
		}
		
		var light, geometry, material, mesh, info;
			
		var container = document.body.appendChild( document.createElement( 'div' ) );	
		container.style.cssText = 'float: right; height: 500px; outline: 0px solid red; padding : 0 0px 30px 30px; top: 0; width: 50%;';
		
		renderer.setSize( window.innerWidth * 0.5, 400 );
		renderer.shadowMapEnabled = true;
		container.appendChild( renderer.domElement );
		scene = new THREE.Scene();
		
		var txt = container.appendChild( document.createElement( 'div' ) );	
		txt.style.cssText = 'float: right; font-size: small;  outline: 1px solid red; text-align: center; top: 410px; width: 100%;';	
		txt.innerHTML = '<i><b>Geneva, San Francisco and Zurich</b><br>' +
			'If you cannot see the three rotating cubes just above, ' +
			'then you will not be able to view most of the apps on this site. Urdacha apps use <a href="http://en.wikipedia.org/wiki/WebGL" target="_blank">WebGL</a> which only runs on recently-made computers. ' +
			'Tablets and smartphones usually do not work. Furthermore, Urdacha\'s apps are currently only being tested on the Google Chrome browser.' +
			'Internet Explorer is definitely not supported. Urdacha apps on FireFox and Safari currently have issues but these can mostly likely be fixed.</i>';

		camera = new THREE.PerspectiveCamera( 40, window.innerWidth / window.innerHeight, 1, 1000 );
		camera.position.set(-30, 30, 30);
		controls = new THREE.TrackballControls( camera, renderer.domElement );
/*
		stats = new Stats();
		stats.domElement.style.cssText = 'position: absolute; top: 0px; zIndex: 100; ';
		document.body.appendChild( stats.domElement );    
*/

		window.addEventListener( 'resize', onWindowResize, false );

		light = new THREE.SpotLight( 0xffffff );
		light.position.set( 200, 400, 200 );
		
//  Assets	

		light = new THREE.DirectionalLight( 0xffffff, 1 );
		light.position.set( 1, 1, 1 ).normalize();
		scene.add( light );

		light = new THREE.DirectionalLight( 0xffffff, 1 );
		light.position.set( -1, -1, -1 ).normalize();
		scene.add( light );
		
		light = new THREE.AmbientLight( 0xffffff);
		light.color.setHSL( 0.1, 0.5, 0.3 );
		scene.add( light );		
		

		light = new THREE.SpotLight( 0xffffff, 1.5 );
		light.position.set( 100, 200, 100 );
		light.castShadow = true;
		
		light.shadowMapWidth = 2048;
		light.shadowMapHeight = 2048;
		light.shadowCameraNear = 230;
		light.shadowCameraFar = 275;
		light.shadowCameraFov = 15;		
		light.shadowDarkness = 0.2;
		scene.add( light );  	
// light.shadowCameraVisible = true;		
/*
		var css = document.body.appendChild( document.createElement('style') );
		css.innerHTML = 'body {background-color: transparent; font: 600 12pt monospace; margin: 0; overflow: hidden; text-align: center; }' +
			'a { color: #f00; text-decoration: none;}  ' +
			'button, input[type=range] { -webkit-appearance: none; background-color: silver; height:20px; opacity: 0.5; width: 80px;}' +
			'input[type="range"]::-webkit-slider-thumb {-webkit-appearance: none; background-color: #666; opacity: 0.5; width: 10px; height: 26px; }' ;
*/
		material = new THREE.MeshBasicMaterial( {color: 0xffffff, side: THREE.DoubleSide } );
		geometry = new THREE.PlaneGeometry( 100, 100, 1, 1 );
		geometry.applyMatrix( new THREE.Matrix4().makeRotationX( - Math.PI / 2 ) );
		plane = new THREE.Mesh( geometry, material );
		plane.position.y = -12;
		plane.receiveShadow = true;
		scene.add( plane );

		scans = new THREE.Object3D();
		
		geometry = new THREE.CubeGeometry( 10, 10, 10 );
		var texture = THREE.ImageUtils.loadTexture( '../images/us-ca-sf.gif' );
		material = new THREE.MeshBasicMaterial( { map: texture } );

		var cube1 = new THREE.Mesh( geometry, material );
		cube1.receiveShadow = true;
		cube1.castShadow = true;			
		// cube1.rotation.set(5, 5, 5);
		scans.add( cube1 );
		
		texture = THREE.ImageUtils.loadTexture( '../images/ch-ge.gif' );
		material = new THREE.MeshBasicMaterial( { map: texture } );
		var cube2 = new THREE.Mesh( geometry, material );
		cube2.receiveShadow = true;
		cube2.castShadow = true;		
		cube2.position.set(5, 5, 5);
		cube2.rotation.set(-10, -10, 10);
		scans.add( cube2 );		
		
		var texture = THREE.ImageUtils.loadTexture( '../images/ch-zh.gif' );
		material = new THREE.MeshBasicMaterial( { map: texture } );
		var cube3 = new THREE.Mesh( geometry, material );
		cube3.receiveShadow = true;
		cube3.castShadow = true;		
		cube3.position.set(-5, -5, -5);
		cube3.rotation.set(10, 1, -1);
		scans.add( cube3 );			
		
		scene.add( scans );
	}

	function animate() {
		requestAnimationFrame( animate );
		controls.update();
		renderer.render( scene, camera );
		// stats.update();
		var tim = clock.elapsedTime;
		
		for (var i = 0, len = scans.children.length; i < len; i++) {
			scans.children[i].rotation.x +=0.005;
			scans.children[i].rotation.y +=0.005;
			scans.children[i].position.x += 5 * Math.sin(tim);
			
			scans.rotation.x += 0.002;
		}
	}

	function colorful( arr, count) {
		var delta = 1.0 / count;
		for (var i = 0; i < count; i++ ) {
			arr.push( i *  delta );
		}
		return arr;
	}	

	function onWindowResize() {
		windowHalfX = window.innerWidth / 2;
		windowHalfY = window.innerHeight / 2;
		camera.aspect = window.innerWidth / window.innerHeight;
		camera.updateProjectionMatrix();
		renderer.setSize( window.innerWidth, window.innerHeight );
	}
	
</script>

<h1>Welcome to the Urdacha home page.</h1>

<p>In the context of the <a href='http://urbanprototyping.org/prototype/challenges/urban-data-challenge-zurich-sf-geneva/' target='_blank'>Urban Data Challenge</a>, 
	the Urdacha team has put together what we hope you will find to be valuable tools in the treatment and mining of big data relating to transporation.</p>
	
<p>The goal of the Challenge is as follows:</p>	

<blockquote>
The Urban Data Challenge seeks to harvest the innovative and creative power of communities around the world to explore urban data sets through visualization.
</blockquote>
<p>Our work revolves around three guiding principles:</p>
<ul>
<li>To create useful and impactful 3D visualizations</li>
<li>To process and analyse huge amounts of real-time data</li>
<li>To provide free, open-source tools and knowledge that anyone can use, apply to other cities or datasets and build upon.</li>
</ul>

<h2>Source Code</h2>
<p>Source code, the data files we built and much more information is available in the Urdacha GitHub repository:</p>
<p><a href='http://github.com/jaanga/urdacha' target='_blank'>github.com/jaanga/urdacha</a> </p>

<h2>Progress Reports</h2>
<p>Given that we are providing free open source tools available to anybody that needs them, it is essential the tools are complete and are in working order. ' +
	There is no deadloine or finish line for this type of work. You can track the progress of our ongoing efforts by clicking on 'Progress Reports' in the left menu.</p>

<h2>Why 3D visualizations?</h2>

<p>The Urdacha team worked on the premise that cities are producing increasingly gigantic volumes of data on a daily basis. As we move forward, finding innovative ways to use and learn from this new wealth of information will allow us "unclog the arteries" with cities that are more interactive, that involve citizens in finding solutions to problems, that are more efficient, diverse and appealing.</p>

<p>Before we are able to do so, however, we are facing the challenge of processing these huge amounts of data, of bringing them down to a human scale, in addition to being constricted by the limitations of 2D.</p>
<p>Like the <a href='http://www.youtube.com/watch?v=aXV-yaFmQNk' target='_blank'> little girl in this video</a>, we are still struggling with the limitations of 2D.</p>

<p>Through our project, we have been able to not only translate the datasets into meaningful information, but we have been able to create  3D visualization tools that let you double-click into the data. It helps you interact with your data and therefore your city. You can <em>see</em>, visualize, understand more information at the same time in a 3-Dimensional world.</p>

<h2>So, can I see it?</h2>

<p>The featured project today is called <a href='http://jaanga.github.com/urdacha/#2_hAxis/Urdacha_competition_entry/Read_Me' target='_blank'>hAxis</a>. 
	hAxis provides users the opportunity for Exploratory Data Analysis through visualizations of real-time data feeds from three different cities. 
	The possibilities in this 3D field are near limitless, and the only limitation of hAxis is the user (and bugs).</p>

<p>The main idea of hAxis is that it displays a certain number of "events" which you will see as conical symbols. These events can chart as many different metrics as are available in the dataset. hAxis therefore enables you to examine trends, to establish correlations, to identify problems, within a system.</p>

<p>When you first load hAxis, you will be greeted with what look like colorful tadpoles moving around. Each tadpole is a bus, color-coded by route, moving around San Francisco. The same data is available for Zurich and Geneva. The generic setting is bus route by longitude by latitude - but any number of metrics can be displayed.</p>

<p>A very rapidly approaching revision includes the ability to single out a number of specific events to display and highlight.</p>

<p>The inherent quality of hAxis and its limitless capabilities, depend on the understanding and vision of the user. Used well, hAxis enables you to compare and contrast data in ways previously impossible thanks to the wealth of information provided to us and 3D tools.</p>

<h2>Demonstration</h2>

<p>Because the interface is still in its young age, here are some ready-for-consumption stills from hAxis that demonstrate the capacity of this tool.</p>

<div style="float:left">
<img src="./images/geneva-d1-seq-lod-vid.png" width="300">
<br>
<small>Geneva Day 1 - Passenger Load</small>
</div>
<div style="float:left">
<img src="./images/sanFrancisco-d1-stp-load-vid.png" width="300">
<br>
<small>San Francisco Day 1 - Passenger Load</small>
</div>
<div style="float:left">
<img src="./images/zurich-d1-stp-lod-vid.png" width="300">
<br>
<small>Zurich Day 1 - Passenger Load</small>
</div>
<br>
<p style="clear:both">The first demonstration we have prepared for you is a look at the same metrics in all three cities.</p>

<p>The metrics chosen are:
<ul><li>Passenger load</li>
<li>Stop id</li>
<li>Route</li>
</ul></p>

<p>This means that the images are showing you what is almost a skewed bell curve in the case of San Francisco and Geneva, representing passenger loads on different buses throughout the system. 
	You will note in both cases that the majority of the loading and unloading occurs in the first half of the bus route, while on the second half of the journey the vehicle is much less full.
	Data for Zurich is probably in the same form but we have data for only about twenty percent of the journey and [as of this writing] it appears that there may be an error in the way we are matching up the two Zurich data sets.
	This error will be rectified in the next day or so.
	If we were watching hAxis display these metrics in real time, as you can for San Francisco <a href='http://jaanga.github.com/urdacha/haxis/r4/index.html#title=Select a day#camType=1#camFov=27#camX=-1.14#camY=-30.55#camZ=298.44#color=9#direction=13#directionString=0#folder=../../improved-csv/sanFrancisco/#fname=sf_day1.csv#rotX=0.102#rotY=-0.004#rotZ=0.006#objCount=300#speed=30#time=15#trailCount=100#trailLength=10#tralEnd=14#trailStart=14#upX=-0.007#upY=0.722#upZ=0.692#x=0#y=5#z=9' target='_blank'>here</a>, we could see the progression of these metrics throughout the day.</p>

<p>The second demonstration is about the sort of information that can be found from the Readout section of hAxis.</p>

<div style="float:left">
<img src="./images/sanFrancisco-d1-readout-passenger-load.png" width="300">
<br>
<small>portion of the hAxis readout</small>
</div>

<p style="clear:both" >In this scenario, we looked at the percent of times during the day a bus made a stop with zero passenger load:
<ul>
<li>Geneva day 1 - 8%</li>
<li>San Francisco day 1 - 5%</li>
<li>Zurich day 1 - 9%</li>
</ul>

<p>In layman's terms, this means that in Geneva on October 10th 2012, 8% of buses had, throughout the day, zero passengers on board when they made a stop. If we go further, we see that 16% of buses made stops with a passenger load of 2 or fewer. The number is 13% for San Francisco, and 14% for Zurich.</p>

<p>The third demonstration is whatever you come up with! Head on over to <a href="http://jaanga.github.com/urdacha/#2_hAxis/Urdacha_competition_entry/hAxis_r4">hAxis</a> to see what you can come up with (please allow a dozen seconds for data to load). Want to take it slow? Our <a href="http://jaanga.github.com/urdacha/#2_hAxis/Urdacha_competition_entry/Read_Me">Readme</a> page might be a good start.</p>

<h2>What else is here?</h2>

<p>Urdacha has played around with a lot of different ideas before settling on hAxis. You might find some of these other projects fun: 
<ul>
<li><a href="http://jaanga.github.com/urdacha/#5_flatLand/Prelimary_Urdacha_project_using_Nextbus_data/Read_Me">Flatland</a>: illustrates bunching and gaps in SF by using the NextBus data on a flat surface</li>
<li><a href="http://jaanga.github.com/urdacha/#3_Improved_CSV/View_the_actual_files_hAxis_and_other_apps_display/Read_Me">CSV files</a>: the CSV files we are sourcing hAxis data from!</li>
<li><a href="http://jaanga.github.com/urdacha/#6_Globes/A_fun_side_project_-_another_perspective_and_another_mode/Read_Me">Globes</a>: new concepts for what could be termed a 'data globe'</li>
<li><a href="http://jaanga.github.com/urdacha/#4_Exploratory_Data_Analysis/An_informal_review_of_what_hAxis_can_help_you_see/Read_Me">Exploratory Data Analysis</a>: what we learned as we went. If you are looking for a narrative explaining the thought process in hAxis, this is it!</li>
</ul></p>

</body>
</html>
